import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import numpy as np
from tensorflow.keras.preprocessing import image
import os

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 20  # ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
DATASET_PATH = r"D:\University Project\Vision\contest\Dataset_for_development\Instagram Photos"

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ GPU ‡πÉ‡∏ä‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Data Augmentation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=30,   # ‡∏´‡∏°‡∏∏‡∏ô‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 30 ‡∏≠‡∏á‡∏®‡∏≤
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    DATASET_PATH,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    DATASET_PATH,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• MobileNetV2 ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô Feature Extractor
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')

# ‚úÖ ‡∏õ‡∏•‡∏î‡∏•‡πá‡∏≠‡∏Å‡∏ö‡∏≤‡∏á‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Fine-tuning
base_model.trainable = True
for layer in base_model.layers[:100]:  # ‡∏•‡πá‡∏≠‡∏Å 100 ‡∏ä‡∏±‡πâ‡∏ô‡πÅ‡∏£‡∏Å
    layer.trainable = False

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
output_layer = Dense(len(train_generator.class_indices), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output_layer)

# ‚úÖ ‡πÉ‡∏ä‡πâ Learning Rate Scheduler ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Training ‡πÑ‡∏õ‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)

# ‚úÖ ‡πÉ‡∏ä‡πâ Early Stopping ‡πÅ‡∏•‡∏∞ Save Model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
checkpoint = ModelCheckpoint("best_food_model.h5", monitor='val_loss', save_best_only=True, verbose=1)

# ‚úÖ ‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# ‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS,
    callbacks=[early_stopping, checkpoint, lr_scheduler]
)

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Train ‡πÄ‡∏™‡∏£‡πá‡∏à
model.save("final_food_detector_model.h5")

print("‚úÖ Training Completed and Model Saved!")


# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
def predict_food(image_path):
    model = keras.models.load_model("best_food_model.h5")  # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    img = image.load_img(image_path, target_size=IMG_SIZE)  # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    img_array = image.img_to_array(img)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô array
    img_array = np.expand_dims(img_array, axis=0)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° batch dimension
    img_array /= 255.0  # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0,1]

    prediction = model.predict(img_array)  # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    predicted_class = np.argmax(prediction)  # ‡∏´‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    class_labels = list(train_generator.class_indices.keys())  # ‡∏î‡∏∂‡∏á label ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤

    return class_labels[predicted_class]  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠ class ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ


# ‚úÖ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
image_path = r"D:\University Project\Vision\contest\test_image.jpg"  # ‡πÉ‡∏™‡πà path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
result = predict_food(image_path)
print(f"üçî Predicted Food Category: {result}")
